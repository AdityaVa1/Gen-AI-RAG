
# Answer these questions with respect to the data in the `dev` set.

## Does the LLM handle begin and end of sentence tokens across models correctly?

```
Answer here.
Explain (with examples if needed) why or why not.
```

### Does your code handle these tokens in the same way?

```
Answer here.
If the answer is no, explain why your answer is better or worse.
```

----


## Does the LLM count n-grams correctly?

```
Answer here.
Explain (with examples if needed) why or why not.
HINT: use the tiny models.
```

### Does your code count n-grams in the same way?

```
Answer here.
If the answer is no, explain why your answer is better or worse.
```


----

## Does the LLM handle OOV tokens correctly?

```
Answer here.
Explain (with examples if needed) why or why not.
```

### Does your code handle OOV tokens in the same way?

```
Answer here.
If the answer is no, explain why your answer is better or worse.
```


----

## Does the LLM compute perplexity correctly?

```
Answer here.
Explain (with examples if needed) why or why not.
```

### Does your code compute perplexity in the same way?

```
Answer here.
If the answer is no, explain why your answer is better or worse.
```


----

## Does the LLM perform add-one smoothing corectly?

```
Answer here.
Explain (with examples if needed) why or why not.
```

### Does your code perform add-one smoothing in the same way?

```
Answer here.
If the answer is no, explain why your answer is better or worse.
```


----

# Other LLM code that is **incorrect**

```
Answer here. Explain with examples.
Write N/A if not applicable.
```